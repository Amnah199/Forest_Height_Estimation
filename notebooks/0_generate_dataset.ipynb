{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lgiesen/forest_height/blob/main/notebooks/0_generate_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "u73c0Q_dtc2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount ('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaXIeWlctulu",
        "outputId": "6244b8c0-b603-4a77-cdaf-0ab3150c9eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the zipped data is uploaded in the root_path folder\n",
        "root_path = 'drive/MyDrive/Colab Notebooks/data/'\n",
        "path_images = f'{root_path}images/'\n",
        "path_masks = f'{root_path}masks/'\n",
        "user = \"lgiesen\"\n",
        "repo = \"forest_height\"\n",
        "!git clone https://github.com/{user}/{repo}.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHOyEgCG4vju",
        "outputId": "6d37683c-acae-4051-ee64-8c2a3cdd82d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'forest_height'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 232 (delta 48), reused 54 (delta 22), pack-reused 137\u001b[K\n",
            "Receiving objects: 100% (232/232), 19.25 MiB | 14.14 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/forest_height/src/generate_data.py"
      ],
      "metadata": {
        "id": "nNDKskC-hrBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_files = [filename for filename in get_files(root_path) if '.zip' in filename]\n",
        "zip_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfEqJ-bvhmSa",
        "outputId": "36c3bc36-974a-4f01-91b9-3bd5ae81c35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['masks_train.zip', 'images_train.zip', 'masks_02.zip', 'images_02.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# unzip data\n",
        "%cd \"drive/MyDrive/Colab Notebooks/data/\"\n",
        "# use -B flag to rename files if there is a file with its name\n",
        "!for f in *.zip; do unzip -B \"$f\"; done\n",
        "%cd ../../../../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j6QFmDk78E9",
        "outputId": "0920beb7-8f14-444a-f5e1-fc58c50789a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/data\n",
            "Archive:  images_02.zip\n",
            "  inflating: images/image_000.npy    \n",
            "  inflating: images/image_001.npy    \n",
            "  inflating: images/image_002.npy    \n",
            "  inflating: images/image_003.npy    \n",
            "  inflating: images/image_004.npy    \n",
            "  inflating: images/image_005.npy    \n",
            "  inflating: images/image_006.npy    \n",
            "  inflating: images/image_007.npy    \n",
            "  inflating: images/image_008.npy    \n",
            "  inflating: images/image_009.npy    \n",
            "  inflating: images/image_010.npy    \n",
            "  inflating: images/image_011.npy    \n",
            "  inflating: images/image_012.npy    \n",
            "  inflating: images/image_013.npy    \n",
            "  inflating: images/image_014.npy    \n",
            "  inflating: images/image_015.npy    \n",
            "  inflating: images/image_016.npy    \n",
            "  inflating: images/image_017.npy    \n",
            "  inflating: images/image_018.npy    \n",
            "  inflating: images/image_019.npy    \n",
            "Archive:  images_train.zip\n",
            "  inflating: images/image_000.npy    \n",
            "  inflating: images/image_001.npy    \n",
            "  inflating: images/image_002.npy    \n",
            "  inflating: images/image_003.npy    \n",
            "  inflating: images/image_004.npy    \n",
            "  inflating: images/image_005.npy    \n",
            "  inflating: images/image_006.npy    \n",
            "  inflating: images/image_007.npy    \n",
            "  inflating: images/image_008.npy    \n",
            "  inflating: images/image_009.npy    \n",
            "  inflating: images/image_010.npy    \n",
            "  inflating: images/image_011.npy    \n",
            "  inflating: images/image_012.npy    \n",
            "  inflating: images/image_013.npy    \n",
            "  inflating: images/image_014.npy    \n",
            "  inflating: images/image_015.npy    \n",
            "  inflating: images/image_016.npy    \n",
            "  inflating: images/image_017.npy    \n",
            "  inflating: images/image_018.npy    \n",
            "  inflating: images/image_019.npy    \n",
            "Archive:  masks_02.zip\n",
            "  inflating: masks/mask_000.npy      \n",
            "  inflating: masks/mask_001.npy      \n",
            "  inflating: masks/mask_002.npy      \n",
            "  inflating: masks/mask_003.npy      \n",
            "  inflating: masks/mask_004.npy      \n",
            "  inflating: masks/mask_005.npy      \n",
            "  inflating: masks/mask_006.npy      \n",
            "  inflating: masks/mask_007.npy      \n",
            "  inflating: masks/mask_008.npy      \n",
            "  inflating: masks/mask_009.npy      \n",
            "  inflating: masks/mask_010.npy      \n",
            "  inflating: masks/mask_011.npy      \n",
            "  inflating: masks/mask_012.npy      \n",
            "  inflating: masks/mask_013.npy      \n",
            "  inflating: masks/mask_014.npy      \n",
            "  inflating: masks/mask_015.npy      \n",
            "  inflating: masks/mask_016.npy      \n",
            "  inflating: masks/mask_017.npy      \n",
            "  inflating: masks/mask_018.npy      \n",
            "  inflating: masks/mask_019.npy      \n",
            "Archive:  masks_train.zip\n",
            "  inflating: masks/mask_000.npy      \n",
            "  inflating: masks/mask_001.npy      \n",
            "  inflating: masks/mask_002.npy      \n",
            "  inflating: masks/mask_003.npy      \n",
            "  inflating: masks/mask_004.npy      \n",
            "  inflating: masks/mask_005.npy      \n",
            "  inflating: masks/mask_006.npy      \n",
            "  inflating: masks/mask_007.npy      \n",
            "  inflating: masks/mask_008.npy      \n",
            "  inflating: masks/mask_009.npy      \n",
            "  inflating: masks/mask_010.npy      \n",
            "  inflating: masks/mask_011.npy      \n",
            "  inflating: masks/mask_012.npy      \n",
            "  inflating: masks/mask_013.npy      \n",
            "  inflating: masks/mask_014.npy      \n",
            "  inflating: masks/mask_015.npy      \n",
            "  inflating: masks/mask_016.npy      \n",
            "  inflating: masks/mask_017.npy      \n",
            "  inflating: masks/mask_018.npy      \n",
            "  inflating: masks/mask_019.npy      \n",
            "/content\n",
            "CPU times: user 368 ms, sys: 61.2 ms, total: 429 ms\n",
            "Wall time: 32.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def get_files(dir):\n",
        "    \"\"\"\n",
        "    Get all files from a directory\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dir: Array of strings\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Array of strings\n",
        "    \"\"\"\n",
        "    return [f for f in listdir(dir) if isfile(join(dir, f))]\n",
        "\n",
        "def extract_data(data_filenames):\n",
        "    \"\"\"\n",
        "    Extract data from zipped files\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_filenames: Array of strings\n",
        "    Path to the train data (default: None)\n",
        "    root_path + filename = complete filepath\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dataset: Tuple of np.ndarray\n",
        "    \"\"\"\n",
        "\n",
        "    # load satellite images by loading the first one and then concatenating the rest\n",
        "    X = np.load(f'{path_images}{get_files(path_images)[0]}')\n",
        "    for filename in get_files(path_images)[1:]:\n",
        "        temp = np.load(f'{path_images}{filename}', allow_pickle=True)\n",
        "        X = np.concatenate((X, temp))\n",
        "    # reshape X to distinguish between image and color channel\n",
        "    num_imgs = len(get_files(path_images))\n",
        "    X = X.reshape((num_imgs, int(X.shape[0]/num_imgs), X.shape[1], X.shape[2]))\n",
        "    # ceil the values at 2000 because clouds have a different reflection value\n",
        "    ceiling = 2000\n",
        "    X[X > ceiling] = ceiling\n",
        "    #scale values between 0 and 1\n",
        "    X = X / ceiling\n",
        "\n",
        "    # load labels by loading the first one and then concatenating the rest\n",
        "    y = np.load(f'{path_masks}{get_files(path_masks)[0]}')\n",
        "    for filename in get_files(path_masks)[1:]:\n",
        "        temp = np.load(f'{path_masks}{filename}', allow_pickle=True)\n",
        "        y = np.concatenate((y, temp))\n",
        "\n",
        "    del temp, ceiling, num_imgs\n",
        "\n",
        "    return (X, y)\n",
        "\n",
        "def extract_labels(X, y):\n",
        "    \"\"\"\n",
        "    Labels are sparse, so they are Get all labels (non-zero elements) from a set of images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X: numpy.ndarray\n",
        "    y: numpy.ndarray\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple of numpy.ndarray\n",
        "    \"\"\"\n",
        "    # extract non-zero value indices from y (= label position) to extract the corresponding X-value\n",
        "    # this has to be done for every image, because X has a different length than y,\n",
        "    # if both are flattened due to more color channels\n",
        "    X_labeled = X[0].flat[np.nonzero(y[0].flat)[0]]\n",
        "\n",
        "    for img_idx in range(1, y.shape[0]):\n",
        "        cur_img_nonzero_indices = np.nonzero(y[img_idx].flat)[0]\n",
        "        corresponding_cur_X_values = X[img_idx].flat[cur_img_nonzero_indices]\n",
        "        X_labeled = np.concatenate((X_labeled, corresponding_cur_X_values))\n",
        "\n",
        "    # y just has one dimension, so no loop is needed\n",
        "    y_labeled = y.flat[np.nonzero(y.flat)[0]]\n",
        "    # the length of X and y has to be the same\n",
        "    assert y_labeled.shape == X_labeled.shape\n",
        "    del corresponding_cur_X_values, cur_img_nonzero_indices\n",
        "    return (X_labeled, y_labeled)\n",
        "\n",
        "def generate_dataset(zip_files):\n",
        "    \"\"\"\n",
        "    Generate a dataset (X_train, X_test, y_train, y_test) based on the location of zip files\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    zip_files: Array of strings\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Numpy.ndarray\n",
        "    \"\"\"\n",
        "    X, y = extract_data(zip_files)\n",
        "    del zip_files\n",
        "    X_labeled, y_labeled = extract_labels(X, y)\n",
        "    del X, y\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=0, shuffle=True)\n",
        "    del X_labeled, y_labeled\n",
        "    return (X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "l5S7cprnPyfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = extract_data(zip_files)"
      ],
      "metadata": {
        "id": "FCHmSYRlUtPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_labeled, y_labeled = extract_labels(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KITgasaxUwpI",
        "outputId": "2b24ef5c-59d4-428e-8aa8-dc12df0f8dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 10, 1024, 1024) (40, 1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train, X_test, y_train, y_test = generate_dataset(zip_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzwzDihE0XyP",
        "outputId": "869a36da-d21e-407e-8619-c61997686318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 10, 1024, 1024) (40, 1024, 1024)\n",
            "CPU times: user 9.02 s, sys: 17.5 s, total: 26.6 s\n",
            "Wall time: 33.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train, X_test, y_train, y_test = generate_dataset(zip_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRFQWozgPKzN",
        "outputId": "253260ee-accb-486c-93e4-4ff237e808e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.3 s, sys: 10.5 s, total: 17.8 s\n",
            "Wall time: 21.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove drive connection as it is no longer needed\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "wJ1a2sqeJhg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}