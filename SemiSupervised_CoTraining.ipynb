{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lgiesen/forest-height/blob/main/SemiSupervised_CoTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6876a8ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6876a8ba",
        "outputId": "08c06382-1f7f-4a28-cec2-60c206c3424d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/DataDa2/images_train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtsR6BMPSDgE",
        "outputId": "5a73658b-9cbd-46f5-9789-db4ed4529951"
      },
      "id": "NtsR6BMPSDgE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/DataDa2/images_train.zip\n",
            "replace images/image_000.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: images/image_000.npy    \n",
            "  inflating: images/image_001.npy    \n",
            "  inflating: images/image_002.npy    \n",
            "  inflating: images/image_003.npy    \n",
            "  inflating: images/image_004.npy    \n",
            "  inflating: images/image_005.npy    \n",
            "  inflating: images/image_006.npy    \n",
            "  inflating: images/image_007.npy    \n",
            "  inflating: images/image_008.npy    \n",
            "  inflating: images/image_009.npy    \n",
            "  inflating: images/image_010.npy    \n",
            "  inflating: images/image_011.npy    \n",
            "  inflating: images/image_012.npy    \n",
            "  inflating: images/image_013.npy    \n",
            "  inflating: images/image_014.npy    \n",
            "  inflating: images/image_015.npy    \n",
            "  inflating: images/image_016.npy    \n",
            "  inflating: images/image_017.npy    \n",
            "  inflating: images/image_018.npy    \n",
            "  inflating: images/image_019.npy    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/DataDa2/masks_train.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak85ua5OSFLO",
        "outputId": "1308e454-438d-4b5b-e412-c152262bd652"
      },
      "id": "Ak85ua5OSFLO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/DataDa2/masks_train.zip\n",
            "replace masks/mask_000.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: masks/mask_000.npy      \n",
            "  inflating: masks/mask_001.npy      \n",
            "  inflating: masks/mask_002.npy      \n",
            "  inflating: masks/mask_003.npy      \n",
            "  inflating: masks/mask_004.npy      \n",
            "  inflating: masks/mask_005.npy      \n",
            "  inflating: masks/mask_006.npy      \n",
            "  inflating: masks/mask_007.npy      \n",
            "  inflating: masks/mask_008.npy      \n",
            "  inflating: masks/mask_009.npy      \n",
            "  inflating: masks/mask_010.npy      \n",
            "  inflating: masks/mask_011.npy      \n",
            "  inflating: masks/mask_012.npy      \n",
            "  inflating: masks/mask_013.npy      \n",
            "  inflating: masks/mask_014.npy      \n",
            "  inflating: masks/mask_015.npy      \n",
            "  inflating: masks/mask_016.npy      \n",
            "  inflating: masks/mask_017.npy      \n",
            "  inflating: masks/mask_018.npy      \n",
            "  inflating: masks/mask_019.npy      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = np.empty((0, 9))\n",
        "\n",
        "for i in range(10):\n",
        "    X = np.load('/content/images/image_00' + str(i) + '.npy')\n",
        "    y = np.load('/content/masks/mask_00' + str(i) + '.npy')\n",
        "\n",
        "    X1 = X[[0, 1, 2, 6, 7, 8, 9]]\n",
        "    X1 = X1.reshape(7, -1).transpose()\n",
        "\n",
        "    y = y.reshape(1, -1).transpose()\n",
        "\n",
        "    # Calculate NDVI\n",
        "    b8 = X[[6]].reshape(1, -1).transpose()\n",
        "    b4 = X[[2]].reshape(1, -1).transpose()\n",
        "\n",
        "    denominator = b8 + b4\n",
        "    ndvi = np.where(denominator != 0, (b8 - b4) / denominator, 0)\n",
        "\n",
        "\n",
        "    # Concatenate the slices with the new column\n",
        "\n",
        "    Xy = np.concatenate((X1, y), axis=1)\n",
        "    index = Xy.shape[1] - 1\n",
        "\n",
        "    left_slice = Xy[:, :index]\n",
        "    right_slice = Xy[:, index:]\n",
        "    Xy = np.concatenate((left_slice, ndvi, right_slice), axis=1)\n",
        "\n",
        "    # Concatenate the arrays along the first axis (number of features)\n",
        "    data = np.concatenate((data, Xy), axis=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R022jMhEPaFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae261227-fbb1-4c07-d66a-a5cb869858ee"
      },
      "id": "R022jMhEPaFK",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-7eed8fb048c9>:20: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ndvi = np.where(denominator != 0, (b8 - b4) / denominator, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10,20):\n",
        "    X = np.load('/content/images/image_0' + str(i) + '.npy')\n",
        "    y = np.load('/content/masks/mask_0' + str(i) + '.npy')\n",
        "    X1 = X[[0, 1, 2, 6, 7, 8, 9]]\n",
        "    X1 = X1.reshape(7, -1).transpose()\n",
        "    y = y.reshape(1, -1).transpose()\n",
        "\n",
        "    # Calculate NDVI\n",
        "    b8 = X[[6]].reshape(1, -1).transpose()\n",
        "    b4 = X[[2]].reshape(1, -1).transpose()\n",
        "    denominator = b8 + b4\n",
        "    ndvi = np.where(denominator != 0, (b8 - b4) / denominator, 0)\n",
        "\n",
        "    # Concatenate the slices with the new column\n",
        "\n",
        "    Xy = np.concatenate((X1, y), axis=1)\n",
        "    index = Xy.shape[1] - 1\n",
        "\n",
        "    left_slice = Xy[:, :index]\n",
        "    right_slice = Xy[:, index:]\n",
        "    Xy = np.concatenate((left_slice, ndvi, right_slice), axis=1)\n",
        "    #Xy_ndvi = np.hstack((Xy, ndvi))\n",
        "\n",
        "    # Concatenate the arrays along the first axis (number of features)\n",
        "    data = np.concatenate((data, Xy), axis=0)\n"
      ],
      "metadata": {
        "id": "jPIvyrIKqJTf"
      },
      "id": "jPIvyrIKqJTf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num = np.count_nonzero(data[:,-1])\n",
        "nonzero = np.nonzero(data[:,-1])\n",
        "zero = np.where(data[:,-1] == 0)[0]\n",
        "labeled_data = data[nonzero]\n",
        "unlabeled_data = data[zero]\n"
      ],
      "metadata": {
        "id": "o6sFwQJAlCeX"
      },
      "id": "o6sFwQJAlCeX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c42b48d3",
      "metadata": {
        "id": "c42b48d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "#X_train, y_train, X_test, y_test = train_test_split(X1,y1, test_size=0.2, random_state=1)\n",
        "\n",
        "# Step 3: Create training and testing sets\n",
        "X_labeled, X_test_labeled, y_labeled, y_test_labeled = train_test_split(\n",
        "    labeled_data[:, :-1],  # Features\n",
        "    labeled_data[:, -1],   # Labels\n",
        "    test_size=0.2,          # Adjust the test size as needed\n",
        "    random_state=11         # Set a random seed for reproducibility\n",
        ")\n",
        "\n",
        "\n",
        "X_unlabeled= unlabeled_data[:, :-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del labeled_data, unlabeled_data"
      ],
      "metadata": {
        "id": "Cc1SUxV6Ils8"
      },
      "id": "Cc1SUxV6Ils8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_unlabeled = np.delete(X_unlabeled, -1, 0 )\n",
        "X_unlabeled.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF1xEkhQM-od",
        "outputId": "08ba4440-0768-447e-e19c-fbdcd95516e9"
      },
      "id": "JF1xEkhQM-od",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20939280, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split unlabeled data into two parts for co-training\n",
        "X_unlabeled_1, X_unlabeled_2 = np.split(X_unlabeled, 2)"
      ],
      "metadata": {
        "id": "tNoZiAOYMnlu"
      },
      "id": "tNoZiAOYMnlu",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create two Random Forest models for co-training\n",
        "model_1 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model_2 = RandomForestRegressor(n_estimators=100, random_state=42)\n"
      ],
      "metadata": {
        "id": "Kk0Eil4iyu_U"
      },
      "id": "Kk0Eil4iyu_U",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Training loop for co-training\n",
        "for epoch in range(3):\n",
        "    # Train each model with labeled data using TensorFlow Dataset\n",
        "\n",
        "    # Create TensorFlow Dataset from labeled data\n",
        "    labeled_dataset = tf.data.Dataset.from_tensor_slices((X_labeled, y_labeled))\n",
        "    labeled_dataset = labeled_dataset.shuffle(buffer_size=len(X_labeled), seed=42).batch(128)\n",
        "\n",
        "    for X_batch, y_batch in labeled_dataset:\n",
        "        model_1.fit(X_batch, y_batch)\n",
        "        model_2.fit(X_batch, y_batch)\n",
        "\n",
        "    # Predict on unlabeled data using each model\n",
        "    y_pred_1 = model_1.predict(X_unlabeled_1)\n",
        "    y_pred_2 = model_2.predict(X_unlabeled_2)\n",
        "\n",
        "    # Select confident predictions from each model\n",
        "    confident_indices_1 = np.where(np.abs(y_pred_1 - y_pred_2) < 2)[0]\n",
        "    confident_indices_2 = np.where(np.abs(y_pred_2 - y_pred_1) < 2)[0]\n",
        "\n",
        "    # Use confident predictions to update labeled data\n",
        "    X_labeled = np.concatenate((X_labeled, X_unlabeled_1[confident_indices_1],X_unlabeled_2[confident_indices_2]))\n",
        "    y_labeled = np.concatenate((y_labeled, y_pred_1[confident_indices_1],y_pred_2[confident_indices_2]))\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "4hkOU1pN3AO7"
      },
      "id": "4hkOU1pN3AO7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final training using all labeled data\n",
        "model_1.fit(X_labeled, y_labeled)\n",
        "model_2.fit(X_labeled, y_labeled)\n",
        "\n",
        "# Evaluation\n",
        "y_pred_test = (model_1.predict(X_test_labeled) + model_2.predict(X_test_labeled)) / 2.0\n",
        "mse = mean_squared_error(y_test_labeled, y_pred_test)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "tzMQSMyXbENM"
      },
      "id": "tzMQSMyXbENM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1f7ab4",
      "metadata": {
        "id": "9a1f7ab4"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# compute RMSE\n",
        "print(\"RMSE: {}\".format(np.sqrt(mean_squared_error(y_test_labeled, y_pred_test))))\n",
        "\n",
        "# visualize predictions vs. true labels\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.scatter(y_pred_test, y_test_labeled, color=\"blue\", alpha=0.5)\n",
        "plt.xticks(rotation=45)\n",
        "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "plt.plot([-1, 83], [-1, 83], 'k--')\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.xlim([-1, 83])\n",
        "plt.ylim([-1, 83])\n",
        "plt.title(\"Evaluation of Random Forest Regression Model \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec63412",
      "metadata": {
        "id": "cec63412"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mae = mean_absolute_error(y_test_labeled, y_pred_test)\n",
        "print(\"Mean Absolute Error:\", mae)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}