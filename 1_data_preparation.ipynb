{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lgiesen/forest-height/blob/main/1_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "u73c0Q_dtc2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive', force_remount=True)\n",
        "root_path = 'drive/MyDrive/Colab Notebooks/data/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaXIeWlctulu",
        "outputId": "efdb21c3-bdf2-4a38-ae1b-f1a2758b8e0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"drive/MyDrive/Colab Notebooks/data//images_train.zip\"\n",
        "# !unzip \"drive/MyDrive/Colab Notebooks/data//masks_train.zip\""
      ],
      "metadata": {
        "id": "9WKot2twB7bs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_images = root_path + 'images/'\n",
        "path_masks = root_path + 'masks/'"
      ],
      "metadata": {
        "id": "Ji5teIxEtbrA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import isfile, join\n",
        "from os import listdir\n",
        "def get_files(dir):\n",
        "  onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
        "  return onlyfiles"
      ],
      "metadata": {
        "id": "75SVlLIWtg6q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.load('/content/images/' + get_files(path_images)[0])\n",
        "\n",
        "for filename in get_files(path_images)[1:]:\n",
        "    temp = np.load('/content/images/' + filename, allow_pickle=True)\n",
        "    X = np.concatenate((X, temp))\n",
        "del temp"
      ],
      "metadata": {
        "id": "CmQ0cyskEEm8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_color_channels = int(X.shape[0]/len(get_files(path_images)))\n",
        "num_images = int(X.shape[0]/num_color_channels)\n",
        "X = np.reshape(X, (num_images, num_color_channels, X.shape[1], X.shape[2]))\n",
        "# X.shape: (20, 10, 1024, 1024)\n",
        "del num_color_channels, num_images"
      ],
      "metadata": {
        "id": "iHPYPjsLG51_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.load('/content/masks/' + get_files(path_masks)[0])\n",
        "\n",
        "for filename in get_files(path_masks)[1:]:\n",
        "    temp = np.load('/content/masks/' + filename, allow_pickle=True)\n",
        "    y = np.concatenate((y, temp))\n",
        "del temp"
      ],
      "metadata": {
        "id": "wUkiiZ6OInif"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove drive connection as it is no longer needed\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "wJ1a2sqeJhg1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ceil the values at 2000 because clouds have a different reflection value\n",
        "ceiling = 2000\n",
        "X[X > ceiling] = ceiling\n",
        "#scale values between 0 and 1\n",
        "X = X/ceiling"
      ],
      "metadata": {
        "id": "QdJeTCRPKg6f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract only parts of the image that are labeled."
      ],
      "metadata": {
        "id": "90lF6QCh7vxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract non-zero value indices from y (= label position) to extract the corresponding X-value\n",
        "# this has to be done for every image, because X has a different length than y,\n",
        "# if both are flattened due to more color channels\n",
        "X_labeled = X[0].flat[np.nonzero(y[0].flat)[0]]\n",
        "for img_idx in range(1, y.shape[0]):\n",
        "  cur_img_nonzero_indices = np.nonzero(y[img_idx].flat)[0]\n",
        "  corresponding_cur_X_values = X[img_idx].flat[cur_img_nonzero_indices]\n",
        "  X_labeled = np.concatenate((X_labeled, corresponding_cur_X_values))"
      ],
      "metadata": {
        "id": "ViucJ-VY_EN6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y just has one dimension, so no loop is needed\n",
        "y_labeled = y.flat[np.nonzero(y.flat)[0]]\n",
        "# the length of X and y has to be the same\n",
        "assert y_labeled.shape == X_labeled.shape"
      ],
      "metadata": {
        "id": "8SLb9XuQDDEK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a first model to label the other pixels of the images."
      ],
      "metadata": {
        "id": "mIkNqDw9D9Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=0, shuffle=True)"
      ],
      "metadata": {
        "id": "bI1xwRNmEgEZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
        "n_estimators = [100, 200, 500] #[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "#min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "#min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               #'min_samples_split': min_samples_split,\n",
        "               #'min_samples_leaf': min_samples_leaf,\n",
        "               #'criterion': ['mse', 'mae'],\n",
        "               'bootstrap': bootstrap}"
      ],
      "metadata": {
        "id": "58dJPvwLEmlA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "GF6fExcSYz7h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# initialize model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# train model\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "kbJwapJxE5G1",
        "outputId": "7276a755-f7da-4ae7-d100-919921247d7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.96 s, sys: 20.3 ms, total: 2.98 s\n",
            "Wall time: 4.81 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# initialize model\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
        "\n",
        "# train model\n",
        "rf_random.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9xDs4sREpBQ",
        "outputId": "41dba075-c38f-4ed7-c6eb-8105347e0fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_random.best_params_"
      ],
      "metadata": {
        "id": "7aFl5tz4Eql1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'n_estimators': 100,\n",
        " 'max_features': 'log2',\n",
        " 'max_depth': 10,\n",
        " 'bootstrap': True}"
      ],
      "metadata": {
        "id": "N1D--qp2b6iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir -p saved_model\n",
        "import joblib\n",
        "# save model\n",
        "joblib.dump(rf, f'{root_path}random_forest.joblib')"
      ],
      "metadata": {
        "id": "KYl1CnK9Zk4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# save model\n",
        "joblib.dump(rf, f'random_forest.joblib')"
      ],
      "metadata": {
        "id": "RvOGd4dpf_tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_rf = joblib.load(\"random_forest.joblib\")\n",
        "del loaded_rf"
      ],
      "metadata": {
        "id": "Eak5hxjigypN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "RS9bGBC9hFLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_accuracy = evaluate(rf_random, X_test, y_test)"
      ],
      "metadata": {
        "id": "_7StwnHhgxVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_random = rf_random.best_estimator_\n",
        "random_accuracy = evaluate(best_random, X_test, y_test)"
      ],
      "metadata": {
        "id": "zxVsYY86gu82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
      ],
      "metadata": {
        "id": "btusrrxGguO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_test.values, y_test, color = 'green')\n",
        "plt.scatter(X_test.values, y_pred, color = 'red')\n",
        "plt.title('Random Forest Regression')\n",
        "plt.xlabel('Pixel')\n",
        "plt.ylabel('Forest Height')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fxw19K5IgtZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = rf_random.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "id": "wFNnLnQNYniN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "vPxI6r84Yu3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_random.predict(X_test)"
      ],
      "metadata": {
        "id": "qaljRrS9Ettw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "print('MAE: ', mean_absolute_error(y_test, y_pred))\n",
        "print('MSE: ', mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JzB-uWPVFp0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "random_forest_tuning = RandomForestRegressor(random_state = 42)\n",
        "param_grid = {\n",
        "   'n_estimators': [100, 200, 500],\n",
        "   'max_features': ['auto', 'sqrt', 'log2'],\n",
        "   'max_depth' : [4,5,6,7,8],\n",
        "   'criterion' :['mse', 'mae']\n",
        "}\n",
        "GSCV = GridSearchCV(estimator=random_forest_tuning, param_grid=param_grid, cv=5)\n",
        "GSCV.fit(X_train, y_train)\n",
        "GSCV.best_params_"
      ],
      "metadata": {
        "id": "Rm3O6ff0Ew0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative loading and storing of data:\n",
        "```\n",
        "# create data sets by combining npy files\n",
        "path_train_sat = root_path + \"train_satellite.npy\"\n",
        "path_train_masks = root_path + \"train_masks.npy\"\n",
        "\n",
        "from os import listdir\n",
        "if not isfile(path_train_sat):\n",
        "  print(\"train satellite dataset is generated\")\n",
        "  # image set\n",
        "  # initialize with the first satellite image\n",
        "  train_satellite = np.load(path_images + listdir(path_images)[0])\n",
        "  # concatinate all other images\n",
        "  for f in listdir(path_images)[1:]:\n",
        "      current_array = np.load(path_images + f, allow_pickle=True)\n",
        "      train_satellite = np.concatenate((train_satellite, current_array), axis=0)\n",
        "  # adjust incorrect shape: (200, 1024, 1024)\n",
        "  train_satellite = train_satellite.reshape(20, 10, 1024, 1024)\n",
        "  # save as file\n",
        "  np.save(path_train_sat, train_satellite, allow_pickle=True, fix_imports=True)\n",
        "if not isfile(path_train_masks):\n",
        "  print(\"train masks dataset is generated\")\n",
        "  # masks\n",
        "  # initialize with the first mask image\n",
        "  train_masks = np.load(path_masks + listdir(path_masks)[0])\n",
        "  # concatinate all other images\n",
        "  for f in listdir(path_masks)[1:]:\n",
        "      current_array = np.load(path_masks + f, allow_pickle=True)\n",
        "      train_masks = np.concatenate((train_masks, current_array), axis=0)\n",
        "  # save as file\n",
        "  np.save(root_path + \"train_masks.npy\", train_masks, allow_pickle=True, fix_imports=True)\n",
        "  ```"
      ],
      "metadata": {
        "id": "u_VPaU_3x3lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Large Images: Creating Cutouts\n",
        "Split the large image into smaller sub-images. Use these for training and prediction."
      ],
      "metadata": {
        "id": "EZJUPVaRmsbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "id": "sADtjrGdKtEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from patchify import patchify, unpatchify\n",
        "\n",
        "patch_shape = (10, 256, 256) # needs to have the same number of dimensions as the whole image\n",
        "step_size = 256 # cuurently exact cropping of images with no overlap\n",
        "\n",
        "# patchify has to be executed for each image individually\n",
        "# initialize all patches with patches from first image. Then add all other patches\n",
        "first_patches = patchify(X[0], patch_shape, step=step_size)\n",
        "all_patches = first_patches\n",
        "for idx in range(1, X.shape[0]):\n",
        "  img = X[idx]\n",
        "  patches = patchify(img, patch_shape, step=step_size)\n",
        "  # add all other patches\n",
        "  all_patches = np.concatenate((all_patches, patches))"
      ],
      "metadata": {
        "id": "sVJ_anmgUvjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if patch shape is as planned\n",
        "assert all_patches.shape == (20, 4, 4, 10, 256, 256)"
      ],
      "metadata": {
        "id": "12W0apVVU3HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if the original image can be reconstructed:"
      ],
      "metadata": {
        "id": "oWDOw8Gcuknx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_reconstructed_images = unpatchify(first_patches, X[0].shape)\n",
        "for idx in range(1, X.shape[0]):\n",
        "  #select single patch to unpatchify it\n",
        "  patches = np.expand_dims(all_patches[idx], 0)\n",
        "  reconstructed_image = unpatchify(patches, X[0].shape)\n",
        "  all_reconstructed_images = np.concatenate((all_reconstructed_images, reconstructed_image))\n",
        "\n",
        "all_reconstructed_images = np.reshape(all_reconstructed_images, X.shape)"
      ],
      "metadata": {
        "id": "bKrqFS13VK9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if unpatchify worked\n",
        "assert (all_reconstructed_images == X).all()"
      ],
      "metadata": {
        "id": "tv_PJKAGdOK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del all_reconstructed_images, reconstructed_image"
      ],
      "metadata": {
        "id": "2_MQKtVfr_p1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put x and y axis patches together\n",
        "all_patches = np.reshape(all_patches, (all_patches.shape[0], all_patches.shape[1]*all_patches.shape[2], all_patches.shape[3], all_patches.shape[4], all_patches.shape[5]))"
      ],
      "metadata": {
        "id": "J-Itaja0uuu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_patch_shape = (patch_shape[1], patch_shape[2]) # adjust to mask dimensions\n",
        "\n",
        "# patchify has to be executed for each image individually\n",
        "# initialize all patches with patches from first image. Then add all other patches\n",
        "all_mask_patches = patchify(y[0], mask_patch_shape, step=step_size)\n",
        "for idx in range(1, y.shape[0]):\n",
        "  img = y[idx]\n",
        "  patches = patchify(img, mask_patch_shape, step=step_size)\n",
        "  # add all other patches\n",
        "  all_mask_patches = np.concatenate((all_mask_patches, patches))\n",
        "del patches"
      ],
      "metadata": {
        "id": "8HJy1aaQtOLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_mask_patches = np.reshape(all_mask_patches, (y.shape[0], all_mask_patches.shape[1]**2, all_mask_patches.shape[2], all_mask_patches.shape[3]))"
      ],
      "metadata": {
        "id": "6NiYW7zVwTah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_color(img):\n",
        "  assert len(img.shape) == 3\n",
        "  # Extract Red, Green, and Blue bands\n",
        "  red = img[2, :, :]\n",
        "  green = img[1, :, :]\n",
        "  blue = img[0, :, :]\n",
        "\n",
        "  # Normalize the bands to [0, 1] range\n",
        "  red_norm = (red - red.min()) / (red.max() - red.min())\n",
        "  green_norm = (green - green.min()) / (green.max() - green.min())\n",
        "  blue_norm = (blue - blue.min()) / (blue.max() - blue.min())\n",
        "\n",
        "  return np.stack((red_norm, green_norm, blue_norm), axis=-1)"
      ],
      "metadata": {
        "id": "Jd_bcMdEru3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(img):\n",
        "    #satellite image\n",
        "    if(len(img.shape) == 3):\n",
        "      img = normalize_color(img)\n",
        "\n",
        "    # Plot the image\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1JnqdclqdOI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "1tEfUr9muPVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    #keras.layers.experimental.preprocessing.RandomRotation(0.4),\n",
        "    #keras.layers.RandomCrop(224, 224)\n",
        "])"
      ],
      "metadata": {
        "id": "eq72PVAYwcXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = normalize_color(all_patches[0][0][0][:3])"
      ],
      "metadata": {
        "id": "OD2Pgkh-pSEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#image = tf.cast(tf.expand_dims(image, 0), tf.float32)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image, training=True)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.subplots_adjust(hspace=0.07, wspace=0.01)\n",
        "  plt.imshow(augmented_image)\n",
        "  plt.axis(\"off\")\n",
        "  #print(augmented_image.shape)\n",
        "  #print(i)\n",
        "  #plot_img(augmented_image)\n",
        "\n",
        "del augmented_image, image"
      ],
      "metadata": {
        "id": "PMGJcn_E4HW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1lFuJ_jWi5m"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversion to tensors\n",
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((all_patches, all_mask_patches))"
      ],
      "metadata": {
        "id": "NqXG1qACBIoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.element_spec"
      ],
      "metadata": {
        "id": "mup66OIWBNuK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}